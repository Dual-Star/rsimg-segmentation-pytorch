## author: xin luo, 
## created: 2023.4.2
## Configure parameters for the model training

import torch
import torch.nn as nn
from dataloader.img_aug import rotate, flip, torch_noise, colorjitter, numpy2tensor
from glob import glob

dir_proj = '/home/xin/Developer-luo/rsimg-segmentation-pytorch'

#### ------------- Model -------------
model_name = 'deeplabv3plus_mobilev2'   ### option: unet, deeplabv3plus, deeplabv3plus_mobilev2, hrnet, gmnet

#### ------------- Directories/files -------------
dir_scene = 'data/s2-dset/s2-scene'
dir_truth = 'data/s2-dset/s2-truth'
### --- validation data
dir_val_patch = 'data/s2-dset/s2-val-patch'            ## single scale patch input, generated by notebooks/dset_val_patch.ipynb
# dir_val_patch = 'data/s2-dset/s2-val-patch-scales'   ## multiscale patch input, generated by notebooks/dset_val_patch.ipynb
### --- train data
paths_scene_tra = sorted(glob(dir_scene+'/*.tif'))[10:]        ## scenes for training (excluding the first 10 validation scenes)
paths_truth_tra = sorted(glob(dir_truth+'/*.tif'))[10:]        ## truth for training
### --- path to save
model_save_name = model_name+'_trained'
path_weights_save = dir_proj + '/model_trained/' + model_save_name+'_weights.pth'
path_metrics_save = dir_proj + '/model_trained/' + model_save_name + '_metrics.csv'
### --- number of bands of the image.
num_bands = 6

#### ------------- Training parameters -------------
patch_size = [256]   ### single scale (e.g., [256]) or multiple scale (e.g., [512, 384, 256]) patch size. 
num_thread_data_load = 10
num_epoch = 200

min_img, max_img = 0, 10000   ## used for s2 image normalization
lr = 0.0002                   ## if use lr_scheduler;
batch_size_tra = 16           ## 
batch_size_val = 16           ## 
loss_bce = nn.BCELoss()       ## selected for binary classification

## ------------- Data tranform/augmentation -------------
transforms_tra = [
        colorjitter(prob=0.25, alpha=0.05, beta=0.05),    # numpy-based, !!!beta should be small
        rotate(prob=0.25),           # numpy-based
        flip(prob=0.25),             # numpy-based
        numpy2tensor(), 
        torch_noise(prob=0.25, std_min=0, std_max=0.1),      # tensor-based
            ]

